[https://www.coverfire.com/articles/queueing-in-the-linux-network-stack/](https://www.coverfire.com/articles/queueing-in-the-linux-network-stack/)

# The model

```
application --> network stack --> queueing discipline --> driver queue --> NIC
                                        (qdisc)           (ring buffer)
```

* The driver queue decouples the kernel and hardware. Thanks to the driver queue, the CPU can do other things after
enqueueing a packet without busy waiting for or polling the NIC to obtain a chance to transmit the packet.
The driver queue contains pointers to data structures rather than data, so the actual data size queued is usually
larger than the number of slots in the queue.

* With the help of NIC, the kernel usually provides offloading features like TCP segmentation offload (TSO),
UDP fragmentation offload (UFO), allowing applications to generate packets exceeding the MTU. In cases where
no NIC hardware support is provided, generic segmentation offload (GSO), implemented by software, would be useful.

* Qdisc, like `pfifo_fast`, is a queue management strategy provided by the kernel. It can implement
complex algorithms, like traffic management, classification, rate shaping, in order to optimize the
use of the driver queue, meanwhile keeping the driver queue simply as a normal FIFO, so that the hardware will not get too complicated.


# Starvation/Throughput v.s. Latency

It's like the two sides of queueing: too large driver queue size would take quite some time
to drain, thus the packing enqueued at last may wait for a long time before being sent out
by NIC (bufferbloat). A possible case is, a packet from a delay-sensitive flow is stuck because the
driver queue is occupied by packets from a "data-bound" program. On the other hand, too small
driver queue may be easy to drain, resulting in starvation of the NIC, which is bad for network
throughput.


# Byte Queue Limit (BQL)

So the size of the driver queue does play a role.

Yes, that's why Linux (>3.3.0) introduces the feature of BQL, which adds
a layer between qdics and the driver queue, to automatically changing the size limit
(not the actual size) of the driver queue.

The rough logic is (stolen directly from the linked article):

```
****
** After adding packets to the queue
****

if the number of queued bytes is over the current LIMIT value then
        disable the queueing of more data to the driver queue

****
** When the hardware has completed sending a batch of packets
** (Referred to as the end of an interval)
****

if the hardware was starved in the interval
        increase LIMIT

else if the hardware was busy during the entire interval (not starved) and there are bytes to transmit
        decrease LIMIT by the number of bytes not transmitted in the interval

if the number of queued bytes is less than LIMIT
        enable the queueing of more data to the buffer
```

In a word, BQL checks after enqueueing and at the end of a trasmission period that
whether the driver queue is used properly. If not, (too much wasted space, starvation ...),
it updates the size limit, to make better use of the driver queue.


# TCP Small Queues

Since the qdisc is usually a queue, the same size problem as for the driver queue can occur
between the network stack and the qdisc.

To solve this problem, Linux (>3.6.0) supports TCP smal queues which adds
a per-TCP-flow limit on the number of bytes that can be queued in the qdisc. But it's only
for TCP.

Some qdiscs use (partially) solve this by using a queue for each network flow, such as
Stochastic Fairness Queueing (SFQ) and Fair Queueing with Controlled Delay (`fq_codel`)


# Management Interface

* To inspect driver queue settings, use `ethtool -g`.

* To adjust offloading settings, use `ethtool -k`.

* For BQL, see `/sys/devices/pci0000:00/0000:00:14.0/net/eth0/queues/tx-0/byte_queue_limits`,
where `pci0000:00:14.0` should be changed to the slot of the device reported by `lspci(8)`.
BQL enabled drivers can be seen from [here](https://www.bufferbloat.net/projects/bloat/wiki/BQL_enabled_drivers/).
Also, the kernel needs to be configured to support BQL, see `zcat /proc/config.gz | grep BQL`.

* For the queue size of the qdisc, use `ifconfig` (shown as `txqueuelen`) or `ip link` (shown as `qlen`).
This number is only used as the default queue size of some qdiscs.

* For TCP small queues, see `/proc/sys/net/ipv4/tcp_limit_output_bytes`.

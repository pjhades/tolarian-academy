\BOOKMARK [1][-]{section.1}{Week\0401}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{SVM 解决的问题}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{线性 SVM 和 QP}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{SVM 的优势}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{Dual SVM 的动机}{section.1}% 5
\BOOKMARK [2][-]{subsection.1.5}{QP\040Lagrange\040Dual}{section.1}% 6
\BOOKMARK [2][-]{subsection.1.6}{Dual\040SVM}{section.1}% 7
\BOOKMARK [1][-]{section.2}{Week\0402}{}% 8
\BOOKMARK [2][-]{subsection.2.1}{Kernel\040Trick}{section.2}% 9
\BOOKMARK [2][-]{subsection.2.2}{多项式 Kernel}{section.2}% 10
\BOOKMARK [2][-]{subsection.2.3}{Gaussian-RBF\040Kernel}{section.2}% 11
\BOOKMARK [2][-]{subsection.2.4}{Kernel 的选择}{section.2}% 12
\BOOKMARK [2][-]{subsection.2.5}{Soft-margin\040SVM}{section.2}% 13
\BOOKMARK [2][-]{subsection.2.6}{模型选择}{section.2}% 14
\BOOKMARK [1][-]{section.3}{Week\0403}{}% 15
\BOOKMARK [2][-]{subsection.3.1}{Soft-margin SVM 与 regularization 的联系}{section.3}% 16
\BOOKMARK [2][-]{subsection.3.2}{SVM 的 error function}{section.3}% 17
\BOOKMARK [2][-]{subsection.3.3}{用 SVM 做 soft binary classification}{section.3}% 18
\BOOKMARK [2][-]{subsection.3.4}{直接在 Z 空间解 logistic 回归}{section.3}% 19
\BOOKMARK [2][-]{subsection.3.5}{Kernel\040Ridge\040Regression}{section.3}% 20
\BOOKMARK [2][-]{subsection.3.6}{用 kernel ridge regression 做分类}{section.3}% 21
\BOOKMARK [2][-]{subsection.3.7}{Support\040Vector\040Regression}{section.3}% 22
\BOOKMARK [2][-]{subsection.3.8}{模型比较}{section.3}% 23
\BOOKMARK [1][-]{section.4}{Week\0404}{}% 24
\BOOKMARK [2][-]{subsection.4.1}{Aggregation}{section.4}% 25
\BOOKMARK [2][-]{subsection.4.2}{Uniform\040Blending}{section.4}% 26
\BOOKMARK [2][-]{subsection.4.3}{Linear\040Blending}{section.4}% 27
\BOOKMARK [2][-]{subsection.4.4}{Any\040Blending}{section.4}% 28
\BOOKMARK [2][-]{subsection.4.5}{Bagging:\040Bootstrap\040Aggregation}{section.4}% 29
\BOOKMARK [2][-]{subsection.4.6}{Adaptive\040Boosting\040\(AdaBoost\)}{section.4}% 30
\BOOKMARK [1][-]{section.5}{Week\0405}{}% 31
\BOOKMARK [2][-]{subsection.5.1}{Decision\040Tree\040&\040CART}{section.5}% 32
\BOOKMARK [2][-]{subsection.5.2}{Pruning}{section.5}% 33
\BOOKMARK [2][-]{subsection.5.3}{Decision Tree 总结}{section.5}% 34
\BOOKMARK [2][-]{subsection.5.4}{Random\040Forest}{section.5}% 35
\BOOKMARK [2][-]{subsection.5.5}{Out-of-bag\040Data}{section.5}% 36
\BOOKMARK [2][-]{subsection.5.6}{特征选择}{section.5}% 37
\BOOKMARK [2][-]{subsection.5.7}{Random Forest 总结}{section.5}% 38
\BOOKMARK [1][-]{section.6}{Week\0406}{}% 39
\BOOKMARK [2][-]{subsection.6.1}{AdaBoosted\040Decision\040Tree}{section.6}% 40
\BOOKMARK [2][-]{subsection.6.2}{AdaBoost\040as\040Functional\040Gradient\040Descent}{section.6}% 41
\BOOKMARK [2][-]{subsection.6.3}{Gradient\040Boosting\040&\040Gradient\040Boosted\040Regression}{section.6}% 42
\BOOKMARK [2][-]{subsection.6.4}{Gradient\040Boosted\040Decision\040Tree}{section.6}% 43
\BOOKMARK [2][-]{subsection.6.5}{Aggregation 的总结}{section.6}% 44
\BOOKMARK [2][-]{subsection.6.6}{Neural\040Network}{section.6}% 45
\BOOKMARK [2][-]{subsection.6.7}{NN 训练 & 反向传播}{section.6}% 46
\BOOKMARK [2][-]{subsection.6.8}{NN 优化和 regularization}{section.6}% 47
\BOOKMARK [1][-]{section.7}{Week\0407}{}% 48
\BOOKMARK [2][-]{subsection.7.1}{Deep\040Learning\040Intro}{section.7}% 49
\BOOKMARK [2][-]{subsection.7.2}{Pre-train\040&\040Autoencoder}{section.7}% 50
\BOOKMARK [2][-]{subsection.7.3}{Autoencoder\040&\040PCA}{section.7}% 51
\BOOKMARK [2][-]{subsection.7.4}{Radial\040Basis\040Function\040Network}{section.7}% 52
\BOOKMARK [2][-]{subsection.7.5}{RBF\040Network\040Training\040&\040k-Means}{section.7}% 53
\BOOKMARK [1][-]{section.8}{Week\0408}{}% 54
\BOOKMARK [2][-]{subsection.8.1}{Matrix\040Factorization\040Intro}{section.8}% 55
\BOOKMARK [2][-]{subsection.8.2}{Matrix\040Factorization\040Learning}{section.8}% 56
\BOOKMARK [2][-]{subsection.8.3}{Learn\040by\040SGD}{section.8}% 57
